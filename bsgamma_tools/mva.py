"""
This is a collection of methods for training and plotting the results of MVA training.

Author: Henrikas Svidras
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import b2plot
plt.style.use("belle2")
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

from PyFastBDT import FastBDT

def split_set (set_to_split, size = 0.5 ,rand_state = np.random.randint(9999)):
    """
    Splits pd.DataFrame or a dictionary and returns regular lists divided at train(1-size)/test(size)
    x is defined as all but last column
    y is defined as all but first column
    Splitting is done after shuffling lists

    Inputs:
        set_to_split : anything that can be converted to a pd.DataFrame (including itself) holding keys and values
        size (default 0.5) : float between 0 and 1, proportion of testing sample
        rand_stat (default generated by numpy): int that defines a random state

    Returns:
        x sample for training : array of size original*(1-size)
        x sample for testing  : array of size original*(size)
        y sample for training : array of size original*(1-size)
        y sample for testing  : array of size original*(size)
    """
    from sklearn.model_selection import train_test_split

    pddf = pd.DataFrame(set_to_split)
    pddf.dropna(inplace=True)
    array=pddf.values
    X = array[:,0:-1]
    Y = array[:,-1]
    train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size = size,random_state=rand_state, shuffle=True)
    return train_x, test_x, train_y, test_y, X, Y

def train_FastBDT (train_x, train_y,depth = 2, num_trees = 1000, shrinkage=0.1, subsample=0.2, flatness_loss=-1.0, number_of_flatness_features=0):
    """
    Trains and returns a FastBDT model.

    Inputs:
        train_x : train sample
        train_y : train labels
        depth (default 2): depth of FastBDT classifier
        num_trees (default 200): number of trees of FastBDT classifier

    Returns:
        model : trained FastBDT Classifier
    """

    model = FastBDT.Classifier(nTrees=num_trees,
                               depth=depth,
                               flatnessLoss=flatness_loss,
                               shrinkage=shrinkage,
                               subsample=subsample,
                               numberOfFlatnessFeatures=number_of_flatness_features)
    model.fit(train_x,train_y)

    return model

def show_ROC (model, train_x, test_x, train_y, test_y, legend_title = 'FastBDT',saveas=None, axis=None, dont_show=False):

    """
    For a trained FastBDT model draws a test and train ROC curve.

    Inputs:
        model   : trained FastBDT Classifier
        train_x : train sample
        test_x  : test sample
        train_y : train labels
        test_y : test labels
        legend_title (default FastBDT): title appearing on legend
        saveas (default None): name of the file in which ROC curve is saved. If None, doesn't save.

    Returns:
        -
    """

    probs = model.predict(test_x)
    probs_train = model.predict(train_x)
    auc = roc_auc_score(test_y,probs)
    auc_train = roc_auc_score(train_y,probs_train)
    print(auc, auc_train)

    # calculate roc curves
    fpr, tpr, _ = roc_curve(test_y, probs)
    fpr_train, tpr_train, _ = roc_curve(train_y, probs_train)

    if axis is None:
        golden = (1 + 5 ** 0.5) / 2
        fig_width = 10
        fig_height = fig_width/golden
        fig, axis  = plt.subplots(1, 1,figsize=(fig_width,fig_height))
    else:
        fig = plt.gcf()

    # plot the roc curve for the model
    axis.plot(1-fpr, tpr, marker=',', label=f'Test,  AUC={auc:.3f}')
    axis.plot(1-fpr_train, tpr_train, marker=',', label=f'Train, AUC={auc_train:.3f}')

    # axis labels
    axis.set_xlabel('Background Rejection')
    axis.set_ylabel('Signal Efficiency')
    axis.set_xlim((0,1))
    axis.set_ylim((0,1))
    # show the legend
    axis.legend(title=legend_title,loc='best')

    if saveas:
      fig.savefig(saveas,bbox_inches='tight')

    if not dont_show:
        # show the plot
        plt.show()

def show_separation(model, train_x, test_x, train_y, test_y, log = False, saveas = None, coeff = 1):
    """
    Inputs:
        model   : trained FastBDT Classifier
        train_x : train sample
        test_x  : test sample
        train_y : train labels
        test_y : test labels
        coeff  : coeff to scale
    Return:
        -
    """
    probs = model.predict(test_x)
    probs_train = model.predict(train_x)

    golden = (1 + 5 ** 0.5) / 2
    fig_width = 10
    fig_height = fig_width/golden
    fig, axis  = plt.subplots(1, 1,figsize=(fig_width,fig_height))

    if coeff==1:
      positive_probs = probs[(test_y==1)]
      negative_probs = probs[(test_y==0)]
      positive_probs_train = probs_train[(train_y==1)]
      negative_probs_train = probs_train[(train_y==0)]
    else:
      positive_probs = [coeff*ent for prob in probs[test_y==1]]
      negative_probs = [coeff*ent for prob in probs[test_y==0]]
      positive_probs_train = [coeff*ent for prob in probs_train[train_y==1]]
      negative_probs_train = [coeff*ent for prob in probs_train[train_y==0]]

    _,bins1,_ = b2plot.hist(negative_probs,fill=True, bins=30, label='Continuum',ax=axis, fillalpha=0.7, density=True)
    _,bins2,_ = b2plot.hist(positive_probs,fill=True, bins=30, label='BB', ax=axis, fillalpha=0.7, density=True)

    b2plot.errorhist(negative_probs_train, bins = bins1,ax = axis,label='Continuum Train', fmt='v',color=sns.xkcd_rgb["denim blue"], density=True)
    b2plot.errorhist(positive_probs_train, bins = bins2,ax = axis,label='BB Train', fmt='^',color=sns.xkcd_rgb["dark red"], density=True)

    axis.set_xlabel('Classifier Output')
    axis.set_ylabel(f'Events/{bins1[1]-bins1[0]:.2f}')
    axis.legend(fontsize=15)

    if log:
        axis.set_yscale('log')
    axis.set_xlim((0,1))

    if saveas:
        fig.savefig(saveas,bbox_inches='tight')

    fig.show()

def equalise_bkg_sig(set_to_equalise, separator = 'isNotContinuumEvent'):
    """
    Makes the amount of signal and background in the dataframe equal. Signal is defined as separator==1.

    Inputs:
        set_to_equalise : anything that can be converted to a pd.DataFrame (including itself) holding keys and values
        separator : some variable name which can divide input sig/bkg. 1 is taken to be sig, 0 to be bkg. Must be len(sig)<len(bkg)
    Returns:
        new : pandas DataFrame holding equal amount of sig and bkg
    """
    pddf = pd.DataFrame(set_to_equalise)

    # separate background and signal
    sig = pddf.query(f'{separator}==1')
    bkg = pddf.query(f'{separator}==0')

    #shuffle background
    shuff_bkg = bkg.sample(frac=1)

    #Take only as many events as there is in signal
    cont_red = shuff_bkg[:len(sig)]

    #Append back and reshuffle
    new = sig.append(cont_red)
    new = new.sample(frac=1)

    return new

def show_feature_importance(model,var_set, norm = 'sum', scale = 'log',saveas = None):
    """
    For a trained FastBDT model draws a test and train ROC curve.

    Inputs:
        model   : trained FastBDT Classifier
        var_set : set holding variable names
        norm    : whether to norm importances by max importance or by sum of all
        scale   : whether to show feature importances in log scale
    Returns:
        - Relative importance list (sorted)
    """
    #get feature names and importances
    feature_importance = model.internFeatureImportance()
    importance_list = [feat[1] for feat in feature_importance.items()]

    if norm == 'max':
      relative_importances = np.array([100.0 * imp / max(importance_list)  for imp in importance_list ])
    elif norm == 'sum':
      relative_importances = np.array([100.0 * imp / sum(importance_list)  for imp in importance_list ])
    else:
      raise ValueError('norm can have either "max" or "sum" as value!')

    sorted_idx = np.argsort(relative_importances)[::-1]

    with sns.axes_style("white"):
        golden = (1 + 5 ** 0.5) / 2
        fig_width = 6
        fig_height = fig_width*golden
        fig, ax  = plt.subplots(1, 1,figsize=(fig_width,fig_height))
        sns.despine()
        ax.set_xlabel("Relative feature importance")
        sns.barplot(
            x=relative_importances[sorted_idx],
            y=np.array(var_set)[sorted_idx],
            palette=sns.cubehelix_palette(n_colors=len(sorted_idx),rot=0.7,),
            orient="h",
            ax=ax)
    ax.set_xscale(scale)
    ax.tick_params(axis='y', labelsize=12)

    if saveas:
        fig.savefig(saveas,bbox_inches='tight')

    fig.show()
    return dict(zip(np.array(var_set)[sorted_idx],relative_importances[sorted_idx]))

def show_corrmatrix(columns,emphasise=0,splitby='isNotContinuumEvent',saveas=None):
    """
    Plots correlations as a heatmap

    Inputs:
        corr       : pd.DataFrame
        emphasise  : emphasises last n vars
        splitby    : variable to compare by
    Returns:
        -
    """
    golden = (1 + 5 ** 0.5) / 2
    fig_width = 6
    fig_height = fig_width*golden
    fig, ax  = plt.subplots(1, 2,figsize=(fig_width*4.5,fig_height))

    cols_for_corr = pd.DataFrame(columns)

    corrMatrix1 = cols_for_corr.query(splitby+'==0')
    corrMatrix1 = corrMatrix1.drop(columns=[splitby]).corr()

    corrMatrix2 = cols_for_corr.query(splitby+'==1')
    corrMatrix2 = corrMatrix2.drop(columns=[splitby]).corr()

    cmap=sns.diverging_palette(10, 220, sep=10, n=7,as_cmap=True)
    sns.heatmap(corrMatrix1, annot=False,cmap=cmap,linewidths=0.1,ax=ax[0],vmin=-1,vmax=1)
    ax[0].tick_params(axis='both', which='both', length=0,rotation=45)
    sns.heatmap(corrMatrix2, annot=False,cmap=cmap,linewidths=0.1,ax=ax[1],vmin=-1,vmax=1)
    ax[1].tick_params(axis='both', which='both', length=0,rotation=45)
    ax[0].set_title('Continuum events',size=25)
    ax[1].set_title('BB events',size=25)
    ax[0].set_ylim(*ax[0].get_xlim())
    ax[1].set_ylim(*ax[1].get_xlim())

    ax[1].invert_yaxis()
    ax[0].invert_yaxis()

    if emphasise > 0:
      ax[0].axhline(len(columns)-1-emphasise, color='black',lw=1)
      ax[0].axvline(len(columns)-1-emphasise, color='black',lw=1)
      ax[1].axhline(len(columns)-1-emphasise, color='black',lw=1)
      ax[1].axvline(len(columns)-1-emphasise, color='black',lw=1)
    if saveas:
        fig.savefig(saveas,bbox_inches='tight')

    fig.show()

def roc_eff_purr_compare(vars_to_compare,train_dataframe,test_dataframe,depth=2,trees=200, saveas = None):
    """
    Plots ROC and efficiency-purity curves comparing trainings from different datasets.

    Inputs:
        vars_to_compare : list of vars to compare  e.g [[[var1,var2],'name'],[[var2,var3],'name2']]
        cuts     : cuts to apply on dataframes as string
        train_dataframe  : RDataFramewith values
        test_dataframe  : RDataFrame with values
        depth    : training depth
        trees    : training trees
        saveas   : if not None then name of file that saves the plot
    Returns:
        -
    """
    golden = (1 + 5 ** 0.5) / 2
    fig_width = 12
    fig_height = fig_width/golden
    fig, ax  = plt.subplots(1, 2,figsize=(fig_width*2,fig_height))
    i=0
    for par_set, name in vars_to_compare:
        print(i, par_set, name)
        train_x = train_dataframe[par_set].values[:,0:-1]
        train_y = train_dataframe[par_set].values[:,-1]
        test_x = test_dataframe[par_set].values[:,0:-1]
        test_y = test_dataframe[par_set].values[:,-1]

        parset_model = train_FastBDT(train_x, train_y, depth =depth, num_trees=trees)

        gbd_probs = parset_model.predict(test_x)
        gbd_auc = roc_auc_score(test_y, gbd_probs)
        gbd_fpr, gbd_tpr, _ = roc_curve(test_y, gbd_probs)

        col = sns.color_palette("colorblind", len(vars_to_compare))[i]
        i+=1
        # plot the roc curve for the model
        ax[0].plot(1-gbd_fpr, gbd_tpr, marker=',', label=f'{name}, ROC={gbd_auc:.3f}',color = col,markevery=20)

        pur,eff = b2plot.analysis.pur_eff_cont(gbd_probs,test_y)
        ax[1].plot(pur,eff, marker=',', label=f'{name}, ROC={gbd_auc:.3f}',color = col,markevery=20)

        # axis labels
        ax[0].set_xlabel('Background rejection')
        ax[0].set_ylabel('Signal efficiency')
        # show the legend
        ax[0].legend(loc='best')
        # set axes
        ax[0].set_xlim((0,1))
        ax[0].set_ylim((0,1))
        ax[1].set_ylim((0,1))
        ax[1].set_xlim((0,1))
        ax[1].set_xlabel('Efficiency')
        ax[1].set_ylabel('Purity')
    if saveas:
      fig.savefig(saveas,bbox_inches='tight',dpi=100)

    fig.show()
